<!DOCTYPE html>
<html>
  <head>
    <link rel="stylesheet" href="style.css">
  </head>
<body>

<div class="container">

<header>
   <h1>Active Appearance Models for Face Modelling</h1>
   <h4>CS 269 Course Project, UCLA</h4>
</header>
  
<nav>
  <ul>
    <li><a href="index.html">Home</a></li>
    <li><a href="results.html">Experimental Results</a></li>
    <li><a href="videos.html">Videos</a></li>
    <li><a href="code.html">Materials</a></li>
    <li><a href="team.html">Team Members</a></li>
  </ul>
</nav>

<article>
  <h1>Abstract -</h1>
  <p>Face modelling has long been a target of research in the realm of computer science due to its many practical applications. However, accurately modelling a face in an image can be both difficult and computationally expensive. One potential avenue for effectively creating a face model from an image is the application of Active Appearance Models (AAM) - a generative, deformable, statistical-based template matching method. The base face model is generated from a series of input data points. To apply this model to an image, we split an image into its shape and texture data, perform Generalized Procrustes Analysis on the shape data, and perform a piece-wise affine warp on the texture data. We test this method on the challenging Helen image dataset (hosted by iBug) and show how Active Appearance Models can efficiently fit images using a pre-trained model.</p>
</article>

<footer>Shubham Mittal (104774903) & Taylor Caulfield (404773737) </footer>

</div>

</body>
</html>
